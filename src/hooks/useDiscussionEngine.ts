import { useState, useRef, useCallback, useEffect } from 'react';
import { PersonalityId } from '@/types/personality';
import { SupportedLanguage } from '@/types/speechRecognition';
import { Gender } from '@/types/gender';
import { DiscussionEngine } from '@/services/DiscussionEngine';
import { SimpleResponseGenerator } from '@/services/SimpleResponseGenerator';
import { useOllama, OllamaConfig } from './useOllama';

export const useDiscussionEngine = (
  initialPersonality: PersonalityId = 'friendly',
  gender: Gender = 'male'
) => {
  const discussionEngineRef = useRef<DiscussionEngine | null>(null);
  const responseGeneratorRef = useRef<SimpleResponseGenerator>(new SimpleResponseGenerator());
  
  // Int√©gration Ollama
  const {
    isAvailable: ollamaAvailable,
    models: ollamaModels,
    isLoading: ollamaLoading,
    config: ollamaConfig,
    updateConfig: updateOllamaConfig,
    generateResponse: generateOllamaResponse,
    refreshModels: refreshOllamaModels,
    checkAvailability: checkOllamaAvailability,
    getCacheStats,
    clearCache
  } = useOllama();
  
  const [engineState, setEngineState] = useState({
    isProcessing: false,
    canBeInterrupted: true,
    emotionalState: 'neutral' as 'neutral' | 'happy' | 'thinking' | 'listening'
  });

  const [conversationHistory, setConversationHistory] = useState<Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>>([]);

  // Initialiser le moteur avec le genre
  useEffect(() => {
    if (!discussionEngineRef.current) {
      discussionEngineRef.current = new DiscussionEngine(initialPersonality, gender);
      discussionEngineRef.current.setStateChangeCallback(setEngineState);
      console.log(`üöÄ Discussion engine initialis√© avec support multilingue et genre: ${gender}`);
    }
  }, [initialPersonality, gender]);

  // Mettre √† jour le genre quand il change
  useEffect(() => {
    if (discussionEngineRef.current) {
      discussionEngineRef.current.setGender(gender);
      console.log(`üë§ Genre mis √† jour: ${gender}`);
    }
  }, [gender]);

  const processMessage = useCallback(async (text: string, language: SupportedLanguage = 'fr'): Promise<string> => {
    console.log(`üß† Traitement du message en ${language} pour genre ${gender}: "${text}"`);
    
    try {
      // Ajouter le message utilisateur √† l'historique
      const newUserMessage = { role: 'user' as const, content: text };
      setConversationHistory(prev => [...prev, newUserMessage]);

      let response: string;

      // Utiliser Ollama si activ√© et disponible
      if (ollamaConfig.enabled && ollamaAvailable && ollamaConfig.selectedModel) {
        console.log(`ü¶ô Utilisation d'Ollama avec le mod√®le: ${ollamaConfig.selectedModel}`);
        
        // Adapter le prompt syst√®me selon la personnalit√© et la langue
        const personalityPrompt = language === 'ar' 
          ? `ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ÿ∞ŸÉŸä ŸàÿØŸàÿØ. ÿ™ŸÉŸÑŸÖ ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÅŸÇÿ∑.`
          : `Tu es un assistant IA ${initialPersonality} et ${gender === 'male' ? 'masculin' : 'f√©minin'}. R√©ponds en fran√ßais uniquement.`;
        
        // Mettre √† jour le prompt syst√®me si n√©cessaire
        const enhancedConfig = {
          ...ollamaConfig,
          systemPrompt: `${personalityPrompt}\n\n${ollamaConfig.systemPrompt}`
        };
        
        response = await generateOllamaResponse(text, conversationHistory);
      } else {
        // Fallback vers le g√©n√©rateur simple
        console.log(`üí≠ Utilisation du g√©n√©rateur simple (Ollama non disponible)`);
        response = responseGeneratorRef.current.generateResponse({
          language,
          userInput: text
        });
      }
      
      // Ajouter la r√©ponse √† l'historique
      const assistantMessage = { role: 'assistant' as const, content: response };
      setConversationHistory(prev => [...prev, assistantMessage]);
      
      // Limiter l'historique √† 20 messages (10 √©changes)
      setConversationHistory(prev => prev.length > 20 ? prev.slice(-20) : prev);
      
      console.log(`‚úÖ R√©ponse g√©n√©r√©e en ${language} pour ${gender}: "${response}"`);
      return response;
    } catch (error) {
      console.error('‚ùå Erreur g√©n√©ration r√©ponse:', error);
      const fallback = language === 'ar' 
        ? 'ÿπÿ∞ÿ±ÿßŸãÿå ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿ±ÿ≥ÿßŸÑÿ™ŸÉ.'
        : 'D√©sol√©, une erreur est survenue lors du traitement de votre message.';
      return fallback;
    }
  }, [gender, ollamaConfig, ollamaAvailable, generateOllamaResponse, conversationHistory, initialPersonality]);

  const interrupt = useCallback(() => {
    if (discussionEngineRef.current) {
      return discussionEngineRef.current.interrupt();
    }
    return false;
  }, []);

  const resetConversation = useCallback(() => {
    if (discussionEngineRef.current) {
      // R√©initialiser avec la personnalit√© actuelle
      discussionEngineRef.current = new DiscussionEngine(initialPersonality);
      discussionEngineRef.current.setStateChangeCallback(setEngineState);
    }
    // R√©initialiser l'historique Ollama
    setConversationHistory([]);
  }, [initialPersonality]);

  const changePersonality = useCallback((personalityId: PersonalityId) => {
    if (discussionEngineRef.current) {
      discussionEngineRef.current.setPersonality(personalityId);
    }
  }, []);

  const getCurrentPersonality = useCallback(() => {
    if (discussionEngineRef.current) {
      return discussionEngineRef.current.getCurrentPersonality();
    }
    // Fallback par d√©faut
    return { id: 'friendly', name: 'Amical' };
  }, []);

  const getConversationExport = useCallback(() => {
    if (discussionEngineRef.current) {
      return discussionEngineRef.current.exportMemory();
    }
    return null;
  }, []);

  const getMemoryStats = useCallback(() => {
    if (discussionEngineRef.current) {
      return discussionEngineRef.current.getMemoryStats();
    }
    return {
      totalMessages: 0,
      sessionDuration: 0,
      userInterests: [],
      userPreferences: [],
      lastInteraction: new Date()
    };
  }, []);

  return {
    engineState,
    memoryStats: getMemoryStats(),
    processMessage,
    interrupt,
    resetConversation,
    getConversationExport,
    changePersonality,
    getCurrentPersonality,
    // Nouvelles propri√©t√©s Ollama avec compression
    ollama: {
      isAvailable: ollamaAvailable,
      models: ollamaModels,
      isLoading: ollamaLoading,
      config: ollamaConfig,
      updateConfig: updateOllamaConfig,
      refreshModels: refreshOllamaModels,
      checkAvailability: checkOllamaAvailability,
      getCacheStats,
      clearCache
    }
  };
};
