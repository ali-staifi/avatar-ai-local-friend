
import { useRef, useEffect, useState, useCallback } from 'react';
import { toast } from 'sonner';
import { voskModelManager, ModelLoadingProgress } from '@/services/VoskModelManager';
import { SupportedLanguage } from '@/types/speechRecognition';

interface UseVoskEngineProps {
  language: SupportedLanguage;
  onResult: (transcript: string) => void;
  onListeningChange: (listening: boolean) => void;
  vadEnabled: boolean;
}

export const useVoskEngine = ({
  language,
  onResult,
  onListeningChange,
  vadEnabled
}: UseVoskEngineProps) => {
  const [modelProgress, setModelProgress] = useState<ModelLoadingProgress[]>([]);
  const [engineStatus, setEngineStatus] = useState<'ready' | 'loading' | 'error'>('ready');
  const voskWorkerRef = useRef<Worker | null>(null);

  useEffect(() => {
    const handleProgress = (progress: ModelLoadingProgress[]) => {
      setModelProgress(progress);
    };

    voskModelManager.onProgressUpdate(handleProgress);
    return () => voskModelManager.offProgressUpdate(handleProgress);
  }, []);

  const simulateVoskTranscription = useCallback((audioSegment?: Float32Array) => {
    console.log(`ðŸŽ¤ Vosk: Traitement segment${audioSegment ? ` (${(audioSegment.length / 16000).toFixed(2)}s)` : ''} en ${language}`);
    
    const mockResults = {
      fr: [
        "Bonjour, comment allez-vous ?", 
        "Pouvez-vous m'aider avec Ã§a ?", 
        "C'est parfait, merci beaucoup",
        "Je voudrais savoir comment faire",
        "D'accord, je comprends maintenant"
      ],
      ar: [
        "Ù…Ø±Ø­Ø¨Ø§ØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ", 
        "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠØŸ", 
        "Ø´ÙƒØ±Ø§ Ø¬Ø²ÙŠÙ„Ø§ Ù„Ùƒ",
        "Ø£Ø±ÙŠØ¯ Ø£Ù† Ø£Ø¹Ø±Ù ÙƒÙŠÙ Ø£ÙØ¹Ù„ Ù‡Ø°Ø§",
        "Ø­Ø³Ù†Ø§ØŒ Ø£ÙÙ‡Ù… Ø§Ù„Ø¢Ù†",
        "Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§",
        "Ù…Ø§ Ø§Ø³Ù…ÙƒØŸ",
        "Ø£ÙŠÙ† ØªØ³ÙƒÙ†ØŸ",
        "ÙƒÙ… Ø¹Ù…Ø±ÙƒØŸ",
        "Ø£Ø­Ø¨ ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
      ]
    };
    
    setTimeout(() => {
      const randomResult = mockResults[language][Math.floor(Math.random() * mockResults[language].length)];
      console.log(`âœ… Vosk: Transcription ${language}: "${randomResult}"`);
      onResult(randomResult);
      onListeningChange(false);
      
      if (audioSegment && vadEnabled) {
        toast.success(`Transcription ${language === 'ar' ? 'arabe' : 'franÃ§aise'} rÃ©ussie`, {
          description: `VAD+Vosk: ${(audioSegment.length / 16000).toFixed(1)}s analysÃ©`
        });
      } else {
        toast.success(`Reconnaissance ${language === 'ar' ? 'arabe' : 'franÃ§aise'}`, {
          description: `Vosk: "${randomResult}"`
        });
      }
    }, 500 + Math.random() * 1000);
  }, [language, onResult, onListeningChange, vadEnabled]);

  const initializeVosk = useCallback(async () => {
    try {
      setEngineStatus('loading');
      
      if (!voskModelManager.isModelLoaded(language)) {
        const langName = language === 'ar' ? 'arabe' : 'franÃ§ais';
        toast.info(`Chargement du modÃ¨le ${langName}`, {
          description: "PremiÃ¨re utilisation, veuillez patienter..."
        });
        await voskModelManager.loadModel(language);
      }

      console.log(`ðŸŽ¤ Vosk initialisÃ© pour ${language}${vadEnabled ? ' avec VAD' : ''}`);
      setEngineStatus('ready');
      
      const langName = language === 'ar' ? 'arabe' : 'franÃ§ais';
      toast.success(`Vosk prÃªt en ${langName}`, {
        description: `Reconnaissance vocale offline${vadEnabled ? ' avec dÃ©tection automatique' : ''} disponible`
      });
    } catch (error) {
      console.error('Erreur initialisation Vosk:', error);
      setEngineStatus('error');
      toast.error("Erreur Vosk", {
        description: `Impossible d'initialiser Vosk pour l'${language === 'ar' ? 'arabe' : 'franÃ§ais'}. Utilisez Web Speech API.`
      });
    }
  }, [language, vadEnabled]);

  const startListening = useCallback(async () => {
    onListeningChange(true);
    const langName = language === 'ar' ? 'arabe' : 'franÃ§ais';
    console.log(`ðŸŽ¤ Vosk dÃ©marrÃ© en ${langName}${vadEnabled ? ' + VAD' : ''}`);
    
    if (!vadEnabled) {
      // Fallback sans VAD pour Vosk
      toast.info(`Ã‰coute Vosk ${langName}`, {
        description: "Parlez maintenant..."
      });
      simulateVoskTranscription();
    } else {
      toast.info(`VAD + Vosk ${langName} actif`, {
        description: "Parlez naturellement, la dÃ©tection est automatique"
      });
    }
    
    return true;
  }, [language, vadEnabled, onListeningChange, simulateVoskTranscription]);

  const stopListening = useCallback(() => {
    onListeningChange(false);
    console.log(`ðŸ›‘ Vosk arrÃªtÃ©`);
  }, [onListeningChange]);

  const isModelLoaded = voskModelManager.isModelLoaded(language);

  return {
    engineStatus,
    modelProgress,
    initializeVosk,
    startListening,
    stopListening,
    simulateVoskTranscription,
    isModelLoaded
  };
};
